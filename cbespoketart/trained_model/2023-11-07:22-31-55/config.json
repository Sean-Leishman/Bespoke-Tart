{"cuda": "true", "load_model": "false", "load_path": "trained_model/", "save_path": "trained_model/", "bert_type": "bert", "bert_finetuning": "false", "bert_pretraining": "bert-base-uncased", "epoch_size": 10, "batch_size": 8, "learning_rate": 0.003, "weight_decay": 0.01, "early_stop": 5, "evaluate": "false", "description": "using a transformer after BERT embedding. predicting tokens", "loss_weight": 5.0, "output_window": 5, "context_window": 2, "max_prior_window": 300, "overwrite": "false", "device": "cuda"}