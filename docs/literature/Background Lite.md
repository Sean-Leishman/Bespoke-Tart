# Fundamentals
### A Simplest Systematic for the Organisation of Turn-Taking for Conversation | Sacks et al. 1974

*source: [https://www.jstor.org/stable/412243]*

Any model must be consistent with a number of observations and constraints. 

The model below is based on an opportunity-based or sharing system regulated by normative rules. The behavioural patterns on this account are the outcome of joint, coordinated determination of turns against a background of an assumption of rights to minimal turns.  

Model is based on a series of observations:
- Organisation is not planned in advance 
- Coordinated in a flexible manner as the dialogue evolves
- "Overwhelmingly one party talks at a time (...). Occurrences of more than one speaker at a time are common but brief (...) Transitions (from one turn to the next) with no gap and no overlap are common. Together with transitions characterised by slight gap or slight overlap, they make up the vast majority of transitions"
From this it is argued that:
- Turn-taking can be analysed using units of speech called **turn-constructional-units *(TCU)***
	- Stretches of speech from one speaker during which the other participants act as listeners
- After each such unit there is the **transition-relevant-phase *(TRP)*** where a turn shift can, but doeS not have to, occur 
	- The current speaker may select a new speaker during which the other participants act as listeners
	- If the current speaker does not select then any participant can self select. The first to start gains the turn 
	- If no other party self-selects, the current speaker may continue 
- To identify **TCUs** and **TRPs**, speech is segmented into **inter-pausal-units *(IPU)*** 
	- Stretches of audio from one speaker without any silence exceeding a certain amount (200ms)
- A turn is a sequence of IPUs from one speaker without any IPUs from another speaker. 
- The exception to the above is a short IPU (**Backchannel**)
- Silence between two IPUs within the same speaker is called **pauses**
- Silence between two IPUs from different speakers is called **gaps**

### Timing in turn-taking and its implications for processing models of language | Levinson & Torreira 2015

*source [https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00731/full]*

Addition of a number of constraints and temporal precision to the model proposed  by [[Sacks et al. 1974]].  
- Turns are mostly short (mean 1680ms, median 1227ms) consisting of one or more interjections, phrases or clauses at the syntactic level, and one or more intonational units at the prosodic level. Turn ends typically occur at points of syntactic and prosodic completion.
- Intra-speaker gaps are longer by ~150ms than inter-speaker gaps suggesting the ordered rules (rights first belong to the next speaker then to the current speaker)
- Lengthy gaps (>700ms) may carry semiotic significance (undesired or unexpected response)
- Overlaps, though common, are brief (mean 275ms at turn-transitions). More common at turn transitions than within turns and mostly involve back-channels, simultaneous first-starts and disfluencies as predicted by Sacks 
- Given the latencies of speech production (>600ms), incoming turns have to be predicted if accurate timing is to be achieved 
- Turn-final cues are prevalent in showing a turn is definitely coming to an end. Typically prosodic (phrase-final syllable lengthening and specific melodic patterns in many intonational languages) but also syntactic (syntactic closure) and in principle could be of other types too (gestural)

The above model is based on the Sacks idea of a sharing system but the alternative system proposed by [[Duncan 1972]] proposes a system entirely controlled by the current speaker who has exclusive rights and signals right to transfer at the end of the turn. ![[Pasted image 20230921153233.jpg]]
The above shows a model of the psycholinguistic model of turn-taking. The paper goes on to cite sources to justify a predictive model of turn-taking 

The above shows the kind of interaction between comprehension and production processes that would be involved in a typical turn-transition. There is an early gist of comprehension with speech act apprehension sent as soon as possible to the production conceptualizer. 
The production system may automatically begin to formulate down to the phonology but actual articulation held in a buffer until the comprehension system signals an imminent completion of the incoming turn. 
Checks for closure on a syntactic and prosodic level and as soon as there are signs of linguistic completion the buffered articulation is released. 

If speakers launched responses as early as possible without turn-final cues we would expect overlapping, no-gap-no-overlap transitions to be the most common, rather than a short gap. 
If speakers launched language planning after a turn-final cue than we would expect the most frequent transition times to involve at least half a second or more rather than short gaps of 100-300ms. 

### Interactional Units in Conversation: Syntactic, Intonational and Pragmatic Resources for the Management of Turns | Ford, Thompson 1996

*source [https://books.google.co.uk/books?hl=en&lr=&id=4m1qBJX1UJIC&oi=fnd&pg=PA134&ots=QQWCBu4l-g&sig=023Hdo9pQxgfB-RZXfOAHtbj6DA&redir_esc=y#v=onepage&q&f=false]*

Studies, primarily, the linguistic features that contribute to turn-taking. 
Specifically two questions:
1. "To what extent is syntactic completion a predictor of turn-completion as validated by an actual speaker change? If intonation and pragmatics are considers, is the prediction stronger?"
2. "Where the convergence of syntactic, intonational and pragmatic completion are not associated with speaker change, are crucial interational factors at work? Can the residue be understood as evidence of the strategic interactional use of a norm?"

*Syntactic completion*, testing whether syntax, as predicted by `Sacks et al.` provides projectable units. 
The paper judges an utterance as syntactically complete if *"in it's discourse context, it could be interpreted as a complete clause, that is, with an overt of directly recoverable predicate, without considering intonation of interactional import"*. They go on to note that *syntactically complete utterances can be extended through further additions, so points of syntactic completion may be incremental*. 

Syntactic completion is not based on an individualistic basis so things like backchannels and answers to questions are included, and so a point of syntactic completion is just a point in the dialogue thus far. 
Includes preceding context as part of recovering previous references. 

They note that *"without considering previous discourse context in this manner, we would have found it difficult to find any "syntactic" completion points*. As such there syntactic completion point examples are judged incrementally, so not from one syntactic completion point to the next. 

Intonational completion is also expanded upon and concludes that they define an intonation unit as a valid, well-established auditory unit and they are completed with features of finality (pitch peaks)

*Pragmatic Completion* is judged as a completion of intonational and conversational action sequencing. 
Locally these pragmatic completion points occur where the speaker is projecting more talk but the listener could take a minimal turn (backchannel). 
Globally, if the point had the property of not projecting anything beyond itself in the way of context. 

Results determined that points of intonational and pragmatic completions are nearly always syntactic completion as well however the reverse is not always true so syntactic completion are not always intonational and pragmatic completion points. As such points of intonational and pragmatic completion from syntactic completion points are a unique set that from a *Complex Transition Relevance Places (CTRPs)* 

Issue with above with interdependence between intonation and pragmatic completion as intonation forms a part of definition of a pragmatic completion. However intonational points itself are still valid.

Found 98.8% of intonational completion points are also syntactic completion points but only 53.5% of the reverse is true. 

Argues that because of syntactic completion points outnumbering CTRPs that syntax is not the strongest predictor (CRTPs predict 71% of actual speaker changes). 

Suggests that intonation plays the role of choosing which syntactically complete utterances are being projected as complete units. 

Generally find that CRTPs correlate with speaker change. Units are defined by convergence of intonational, syntactic and pragmatic completion. 

Three quarters of speaker changes occur at a CRTP and about half of the CRTPs were accompanied by speaker changes. 

**Question the result of syntactic completion being the least reliable indicator (of any sort of completion?) as there aren't specific figures to back this up**

### The Use of Content & Timing to Predict Turn Transitions | Garrod, Pickering 2015

*source [https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00751/full]*

Demonstrates the psycholinguistic model of the prediction of the speaker's conclusion and prediction of what linguistic forms will be used. While doing so they will predict a response

Draws on [Pickering and Garrod 2013a]() where the addressee imitates the speaker's utterance and as such use it to determine the intention that underlies their upcoming utterance. As such the addressee can predict when and how the utterance will end, and also to drive their own production mechanisms that predict timing and content.

Mentions a few experimental studies where people predict aspects of upcoming words as well as their syntactic features. 

Emphasises the timing mechanism that relies on entrainment of low-frequency oscillations between speech envelope and brain. 

The author infers that as humans already predict multiple aspects of speech such as syntactic features, sound, constituent structure we can draw local predictions of words and other linguistic information to predict turn endings. This could also be extended to semantics and pragmatics over a much longer period of time. 
This information could come from the current utterance, right before the prediction is required, from non-linguistic context or other background context, but usually far prior to when it is used or required. 
As such the listener can predict the speaker's speech act prior to completion, the length of an utterance and so from this information, how long the speaker will speak about, on what subject, with some speech rate and as such predicting the content and timing of the response. 

A listener can predict the speaker's utterance using *prediction-by-simulation* where the listener combines interpretation of the context and covert imitation of the speaker's prior utterance to estimate the intention and so the listener uses the intention to predict the speaker;'s completion in the same way the listener would produce their own utterance. 

### Projecting the End of a Speaker's Turn: A Cognitive Cornerstone of Conversation | de Ruiter et al. 2006

*source [https://muse.jhu.edu/article/207200]*

Tested hypothesis based on the principle of the prediction or projection of the completion of a current speaker's turn:
- Lexicosyntactic cues
- Intonational contours
By manipulating symbolic content and intonational contour in recordings of natural conversation and subjects are tasked with predicting the end of turn. 

They found that symbolic content of an utterance is necessary for projection the moment of its completion and as such, for regulating turn-content. While intonational contour is neither necessary or sufficient for end-of-turn projection 

Good introduction of the level of simultaneous processing required in conversation and the kind or pressure or 'threat-to-face' [[Brown & Levinson 1978]]

Author notes studies that have claimed that intonational cues are used to project turn endings at the end of turns. However it is noted that the cues may be occurring too late to allow the listener to anticipate the end of a turn. Also although certain intonational phenomena cooccur with turn endings does not meant they are used by the listener as anticipatory cues for projection. 

Notes that [[Schegloff 1996]] is not vulnerable as that pitch cue occurs before the end of the turn. 

Studies such as [[Schaffer 1983]] noted the importance of lexical information over prosodic information but the participants were not under any time pressure to make their judgement like in real-time conversation 

Data is in Dutch. 

The conclusion raised questions for subsequent features such as what accounts for the observed differences in function of intonation and lexicosyntax? Lexicosyntactic information is symbolic, conventionally coded and hierarchically structured whereas intonational information is iconic and indexical and so more likely to be language-independent. 
Symbolic information strongly determines the interpretation of associated nonsymbolic information 

Also they consider by which precise mechanism is lexicosyntactic structure signally the timing of turn completion. Does it just apply to Dutch or is lexicosyntactic structure universally a better sour for end-of-turn prediction. As such one should consider , the informational properties of unfolding syntactic sequence and the available degrees of expressive freedom available. 
Thinking about it, how can emerging, yet unfinished structure of an utterance allow the listener to project completion. Forcing us to think of lexicosyntax as a temporally unfolding structure which display information about itself through the course of its development. 

The turn-taking problem causes us to think about syntax and cognition in new ways. Syntactic structure is an inherently temporal resource for listeners to chart out the course of a speaker's expression and to plan their own speech accordingly. 
A speaker can exploit available lexicosyntactic options to actively foreshadow structure and as such manipulating the unfolding course of the interaction itself and as such controlling the interlocutor's process of cognition and action. 

###  | Magyari and De Ruiter 2012
If a group of listeners attempt to predict the remaining words in De Ruiter (2006) turn fragments and the prediction was more precise then the listeners made more accurate predictions. As such it can be assumed that people's prediction of words are factors that are used to predict turn-endings. 
# Deep-Learning Approaches
### Towards a General, Continuous Model of Turn-taking in Spoken Dialogue using LSTM Recurrent Neural Networks | Skantze 2017

*source: [https://aclanthology.org/W17-5527/]*

Predictive, continuous model made up of LSTM RNN units trained on human-human dialogue
A general model not trained for a specific purpose, just to predict future voice activity of each speaker. 
This model is then applied to two specific use cases:
- Whether a turn-shift occurs or not in pauses
- Predicts whether an utterance, at onset, will be a short or long utterance

Uses MAE as loss function. 

Trained & evaluated on the HCRC Map Task corpus. 
![[Pasted image 20230918211939.png]]

### Investigating Speech Features for Continuous Turn-Taking Prediction Using LSTMs | Roddy et al. 2018

*source (https://arxiv.org/pdf/1806.11461.pdf)*

Extends work of [[Skantze 2017b - Towards a General Continuous Model of Turn-Taking in Spoken Dialogue using LSTMs|Skantze 2017]] and investigates the effect of additional speech feature types: acoustic, phonetic, linguistic. Sequential forward selection is used to determine which acoustic feature is most useful. 

Uses BCE as loss function as improvement over [[Skantze 2017b - Towards a General Continuous Model of Turn-Taking in Spoken Dialogue using LSTMs|Skantze 2017]]. 

Tests three predictions:
- Predictions at pauses
- Predictions at onsets (short vs long)
- Prediction at overlap (whether system should stop speaking if user interrupts)

[[Datasets|HCRC map task]] corpus is used for training and evalutation. 

### Multimodal continuous turn-taking prediction using multiscale RNNs

*source: [here](http://www.tara.tcd.ie/bitstream/handle/2262/89623/p186-roddy.pdf?sequence=1&isAllowed=y)*

Improves on [[Skantze 2017b - Towards a General Continuous Model of Turn-Taking in Spoken Dialogue using LSTMs|Skantze 2017]] by proposing a multiscale RNN architecture in which separate modalities are modelled in separate sub-networks operating on individualistic timescales. This is then fused in a master LSTM by concatenating the hidden networks of the sub-networks

[[Datasets|HCRC map task]] corpus is used for training and evalutation. 
[[Datasets|Mahnob Mimicry Database]] is used for visual and acoustic modalities

Faster rate of sampling for acoustic/phonetic features combined with slower rate of sampling of context works best ![[Pasted image 20230918213133.png]]

### TurnGPT: a Transformer-based Language Model for Predicting Turn-taking in Spoken Dialog | Ekstedt, Skantze 2020

*source: [here](https://aclanthology.org/2020.findings-emnlp.268.pdf)*

A novel approach, transformer-based language model fine-tuned on dialogue datasets in order to predict turn-completion based off of linguistic features only.

Fine-tuned both GPT-2 and DialoGPT, smallest versions, with 12 layers, 12 heads and 768 hidden units. 

Adds additional tokens as a speaker token and also turn-shift tokens. Training is done via cross-entropy loss.

Baselines: POS bigrams with simple model; LSTM model 

**[[Datasets]]:** 
1. Task-oriented dialog system corpora (user & automated assistant)
	1. Taskmaster
	2. MetaLWOZ
	3. Mutliwoz 2.1
	4. Coached Conversational Preference Elicitation (CCPE)
2. Human-human written dialogue
	1. Persona
	2. Daily Dialog
3. Spontaneous spoken dialog between two humans:
	1. HCRC Maptask
	2. Switchboard

Combined to form a full dataset

For the spontaneous dataset:
A custom turn policy is implemented. Backchannels are present in the data and so removed from the dialog if spoken in isolation, separated by more than one second from other utterances made by the same speaker. 
IPUs are defined as utterances separated by less than 500ms. IPUs spoken completely inside another IPU made by the other speaker, were omitted. 
Turns are created by merging all consecutive IPUs from one speaker separated by mutual silence. 

### Voice Activity Projection
![[Pasted image 20230919005506.png]]
