# Questions
- How much emphasis should be placed in the background research for related work or theoretical background of turn-taking
	- Related work can mean BERT, transfer learning, LSTM RNNs for turn-taking, TurnGPT
- What should be predicted?     
    - TRP classification 
    - Tokens
- How data should be represented? 
    - In order to use context and multiple turns in the data 
- Any additional data?
    - voice activity data in order to account for backchannels and overlaps
- Solving imbalanced class issue
- Multi-modality?
- Simulating turn-prediction and if the system should perform in real-time
- Questions as listed in the email provided 
- Thoughts about classifying each utterance as a probablitic units rather than as a bianry notion of a TRP to hold the predictive element of turn-taking.
    - In practive this could entail predicting the distance is from an utterance and with that a kind of probabalisitc notion of turn-taking
        - e.g. full utterance -> "This is a beautiful bridge, isn't it? <EOT>" Distance 0.0, Probability 1.0 of TRP
        - e.g. half-utterance -> "This is a beautiful bridge" Distance 3 tokens so Probability < 1 of a TRP

Word embedding papers feeds the NN architecture for nlp tasks
look into machine tranlation models for examples of how nlp problems were solved
interspeech conference for speech based features
learn something from intermediate phrase where feature engineering is emphasised 

look into differences of languages in text and difference between datasets and how the styles of transcription differ
look more into edinburgh accents and switchboard 
think about backchannels as informing a turn so rather than purely predicting a turn a multitask approach of also predicted a backchannel
reward more for a trp rather than a nontrp
reward more for things thatually happen rather than penalise perfreclty vali choices. proabbility type metric. so rather than letting the model coast with just zeros or predicting very obvious turn predictions try and reward correct difficult predictions. 

contrastive loss option where contexts taken prior to a mask and contexts after a make after contrasted using the loss so that the prior contexts are informed of the possible future contexts

Implement other metrics such as f1 score that don't try to gain additional evaluation marks

for pretraining of the model: POS prediction/next word prediction/topic boundary unsupervised, ligthweight, predict topic, to gain a greater context 
regularization - predicting liklihood of a shift for the next word, next 5 words, next 10 words etc. 
debugging with masked lm and speaker tokens so using the bidirectional context that takes both sides of the context into account

background: catgorise based on features and how certain papers of philosophies fit into that

meet on 16/10 Monday 11
