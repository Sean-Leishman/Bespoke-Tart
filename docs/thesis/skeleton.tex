% UG project example file, February 2022
%   A minior change in citation, September 2023 [HS]
% Do not change the first two lines of code, except you may delete "logo," if causing problems.
% Understand any problems and seek approval before assuming it's ok to remove ugcheck.
\documentclass[logo,bsc,singlespacing,parskip]{infthesis}
\usepackage{ugcheck}

% Include any packages you need below, but don't include any that change the page
% layout or style of the dissertation. By including the ugcheck package above,
% you should catch most accidental changes of page layout though.

\usepackage{microtype} % recommended, but you can remove if it causes problems
\usepackage{natbib} % recommended for citations

\begin{document}
\begin{preliminary}

\title{End-of-Turn Detection}

\author{Sean Leishman}

% CHOOSE YOUR DEGREE a):
% please leave just one of the following un-commented
%\course{Artificial Intelligence}
%\course{Artificial Intelligence and Computer Science}
%\course{Artificial Intelligence and Mathematics}
%\course{Artificial Intelligence and Software Engineering}
%\course{Cognitive Science}
%\course{Computer Science}
%\course{Computer Science and Management Science}
%\course{Computer Science and Mathematics}
%\course{Computer Science and Physics}
%\course{Software Engineering}
\course{Master of Informatics} % MInf students

% CHOOSE YOUR DEGREE b):
% please leave just one of the following un-commented
\project{MInf Project (Part 1) Report}  % 4th year MInf students
%\project{MInf Project (Part 2) Report}  % 5th year MInf students
%\project{4th Year Project Report}        % all other UG4 students


\date{\today}

\abstract{
This skeleton demonstrates how to use the \texttt{infthesis} style for
undergraduate dissertations in the School of Informatics. It also emphasises the
page limit, and that you must not deviate from the required style.
The file \texttt{skeleton.tex} generates this document and should be used as a
starting point for your thesis. Replace this abstract text with a concise
summary of your report.
}

\maketitle

\newenvironment{ethics}
   {\begin{frontenv}{Research Ethics Approval}{\LARGE}}
   {\end{frontenv}\newpage}

\begin{ethics}
\textbf{Instructions:} \emph{Agree with your supervisor which
statement you need to include. Then delete the statement that you are not using,
and the instructions in italics.\\
\textbf{Either complete and include this statement:}}\\ % DELETE THESE INSTRUCTIONS
%
% IF ETHICS APPROVAL WAS REQUIRED:
This project obtained approval from the Informatics Research Ethics committee.\\
Ethics application number: ???\\
Date when approval was obtained: YYYY-MM-DD\\
%
\emph{[If the project required human participants, edit as appropriate, otherwise delete:]}\\ % DELETE THIS LINE
The participants' information sheet and a consent form are included in the appendix.\\
%
% IF ETHICS APPROVAL WAS NOT REQUIRED:
\textbf{\emph{Or include this statement:}}\\ % DELETE THIS LINE
This project was planned in accordance with the Informatics Research
Ethics policy. It did not involve any aspects that required approval
from the Informatics Research Ethics committee.

\standarddeclaration
\end{ethics}


\begin{acknowledgements}
Any acknowledgements go here.
\end{acknowledgements}


\tableofcontents
\end{preliminary}


\chapter{Introduction}

The preliminary material of your report should contain:
\begin{itemize}
\item
The title page.
\item
An abstract page.
\item
Declaration of ethics and own work.
\item
Optionally an acknowledgements page.
\item
The table of contents.
\end{itemize}

As in this example \texttt{skeleton.tex}, the above material should be
included between:
\begin{verbatim}
\begin{preliminary}
    ...
\end{preliminary}
\end{verbatim}
This style file uses roman numeral page numbers for the preliminary material.

The main content of the dissertation, starting with the first chapter,
starts with page~1. \emph{\textbf{The main content must not go beyond page~40.}}

The report then contains a bibliography and any appendices, which may go beyond
page~40. The appendices are only for any supporting material that's important to
go on record. However, you cannot assume markers of dissertations will read them.

You may not change the dissertation format (e.g., reduce the font size, change
the margins, or reduce the line spacing from the default single spacing). Be
careful if you copy-paste packages into your document preamble from elsewhere.
Some \LaTeX{} packages, such as \texttt{fullpage} or \texttt{savetrees}, change
the margins of your document. Do not include them!

Over-length or incorrectly-formatted dissertations will not be accepted and you
would have to modify your dissertation and resubmit. You cannot assume we will
check your submission before the final deadline and if it requires resubmission
after the deadline to conform to the page and style requirements you will be
subject to the usual late penalties based on your final submission time.

\chapter{Background Review}
\section{Turn-taking: From the Conversational Analysis Perspective}
Over the last few decades, psycholinguists have been fascinated with the complexity of the mechanisms of conversation along with the apparent ease with which speaker's are able to converse in a orderly and timely manner. 
\cite{Sacks1974} is a widely cited paper that outlines some general observations that has gone on to inform general turn-taking literature. They observed that turn-taking organisation is not planned in advance however the actions taken are still coordinated, in a flexible manner that can be decided upon by the current participants in a conversation; typically one person speaks at a time and most transitions have a small gap or overlap but transitions do also occur with no gap and no overlap. 
Automatic analysis has managed to substantiate these claims with the existence of generally short turns (mean 1680ms, median 1227ms) (\cite{LevTor2015}) and that, the majority of turn transitions (51\%-55\%) take places under 200ms (\cite{HelEdl2010}). An even greater majority of turn transitions take place between -100ms and 500ms (\cite{LevTor2015}). Turn-taking is finely tuned and managed.

\subsection{Models of Turn-taking Organisation} 
Turn-taking organisation has generally been characterised in two different ways within literature: the \texttt{reactionary} and the \texttt{predictive} approach.
The former assumes that participants simply understand end-of-turn signals and react to them accordingly while the predictive approach entails the listener predicting the end of turn in advance such that responses are well timed. 

The reactionary approach assumes that turn-taking organisation is regulated by both vocal and gestural signals (\cite{Yngve1970}). This approach was pioneered by (\cite{Duncan1972, Duncan1973, Duncan1974, Duncan1977}) who argued for a precise set of context free turn-yielding 'signals'. \cite{Duncan1972} described phrase-final intonation, drawl on the final syllable, termination of hand gesticulation, changes in pitch and a termination of a grammatical clause as turn-yielding signals. 

Others have argued against the general model of a reactionary approach as, put simply, turn-transitions occur too quickly and turn-yielding signals occur too late within a speaker's utterance for the listener to simply react to an end-of-turn signal (\cite{LevTor2015, Riest2015}). (It is important to note that the \texttt{reactionary} approach is only dismissed in the context of the entire psycholinguistic model where both production and comprehension is considered.) 

\cite{Sacks1974} pioneered the \texttt{predictive} approach and in their analysis of turn-taking argued that the observed speed of turn-transitions required some form of `projection` with the production of language beginning prior to the end of a turn. This model of turn-taking is based off of separating speech into units, where one participant is the speaker, called \texttt{Turn Construction Units (TCU)} and immediately after completing a TCU a \texttt{Transition Relevance Place (TRP)} occurs that signals that a turn-transition (turn-shift) can occur. It is also important to note that a TRP does not always result in a turn-shift and a turn-shift does not always occur at a TRP. Nevertheless, every TRP is governed by a set of rules determining whether or not a TRP will result in a turn-shift: 
\begin{enumerate}
    \item{} The current speaker may select a new speaker during which the other participants act as listeners 
    \item{} If the current speaker does not select then any participant can self-select. The first to start gains the turn.
    \item{} If no other party self-selects, the current speaker may continue. 
\end{enumerate} 

The rules highlights an interesting property of turn-taking, first noted by \cite{Sacks1974} and verified by \cite{tenBosch2005}, that intra-speaker gaps (gaps within the same utterance) are longer than inter-speaker gaps (gap resulting in a turn-shift) by around 25\%.

\cite{Sacks1974} note that in order for a listener to project the end-of-turn than the speaker would have to construct their turns, with successive TCUs, in such a way that a turn transition is foreshadowed, showing that the turn is, in effect, winding down.

Some effort has been taken by \cite{HelEdl2010} to critique the \texttt{predictive} approach. They argued that the systematic properties outlined within \cite{Sacks1974} are not consistent with observed data. 
This claim originates from the number of turn transitions above 200ms (41\%-45\% \cite{HelEdl2010}) and for these turn transitions, listeners are reacting to silence or reacting to phrase-final prosodic information. \cite{LevTor2015} comprehensibly dismisses the claim by citing it takes for a silence to be recognisable, the reaction to the silence and any production of speech, where they claim the process would take 550ms. In addition to this, \cite{Riest2015} point out that the presence of longer gaps could be explained by a speaker intentionally delaying a response when producing a 'dispreferred' response (\cite{Lev1983, KenTor2014}). The existence of phrase-final cues that contribute to turn-taking however, is an area of debate that could explain the complexities within the organisation of turn-taking. 

\subsection{Turn-taking Cues}
The question remains, what features of speech are relevant when predicting a TCU completion and, as such, when completing a turn? 
Prior research related to turn-yielding signals (\cite{Duncan1972}), pointed out prosodic, syntactic and gestural features that coincide with turn-completion at an end-of-turn. Later work focussed on these turn-yielding signals and which signals contribute in a meaningful manner such that the listener is able to project a turn-completion. 
Most work has focussed on three aspects of conversation: syntactic, prosodic and pragmatic features. Gestural features (\cite{Duncan1972}) and gaze (\cite{Kendon1967}) have shown to be a useful part of turn-taking but findings in gaze have suggested these features are action dependent and more context-sensitive than other features (\cite{Clayman2013}).

Although \cite{Sacks1974} left solving the question of how projection occurs they suggested that syntax to future research but they suggested that syntax and semantics contributed more due to the projectibility of syntactic units as compared to the projectibility of prosodic units. 

The complex nature of turn-taking and the constraints imposed by language production means that turn-taking cues have to be early enough in order to determine a turn-completion and to generate some kind of response. With knowledge of the temporal requirements \cite{deRuiter2006} tasked participants to predict a turn-completion both when intonational contours have been removed and then when lexicosyntactic information is removed. They found that performance was unaffected by the removal of intonational context but it was heavily affected by the removal of lexicosyntactic information concluding that lexicosyntactic information is necessary for turn-taking and tentatively sufficient for turn-taking while this is not the case for intonational information. 
This study was backed up by \cite{Magyari2012} that when participants predicted the remaining part of a sentence they were more accurate in predicting a turn-completion which could be due to a listener predicting the content of the sentence, as such predicting the length of the remaining utterance. This belief was also highlighted by \cite{PicGar2013} who found that listeners actually imitate the speaker to determine intention and as such the content which is combined with the speaker's speaking rate to correctly time their own prepared utterance.

However, purely considering lexicosyntactic information may result in predicting turn-shifts too frequently due to the prevalence of syntactic completeness points (\cite{Ford1996}) within sentences. For example (taken from \cite{Ford1996}):

\begin{quote}
    V: And his knee was being worn/- okay/ wait./
    It was bent/ that way/
\end{quote}

Here `/` represents a syntactic completion points where an utterance is syntactically complete if "in its discourse context, it could be interpreted as a complete clause, that is, with an overt or directly recoverable predicate, without considering intonation or interactional import". With so many syntactic completion points it is important to determine the differences between those to find correct TRPs. \cite{Ford1996} did so by defining a point of syntactic, intonational and pragmatic completeness as a \texttt{Complex Transition Relevant Phrase (CRTP)} where 71\% of CRTPs are turnshifts. In this instance, intonational completeness refers to a completion of an intonational unit containing a single coherent intonational contour (\cite{DuBois1993}) and pragmatic completeness refers to a point of intonational completeness with a complete conversational action. The importance of pragmatics is seen in \cite{PicGar2013} due to its description and reliance on intention to predict a turn-completion. 

However, it may be important to determine the differences in what may or may not be used in determining a turn-completion. In \cite{PicGar2013} speaker intention plays an important role in allowing the listener to ultimately predict the end of an utterance. The role of intention aligns well with what is can be described as `action` as in \cite{Levinson2012} and `pragmatics` within \cite{Ford1996} (although their definition considers intonation). As such the removal of lexicosyntactic information as in \cite{deRuiter2006} and the resulting effects could be related to the overall removal of pragmatics. 

\cite{Ford1996} theorised that TCUs and their partnering TRPs are a complex notion and as such multiple factors should be considered for predicting a turn completion. This belief was tested by \cite{BogTor2015} who also sought to refute the claim that intonation had no effect on turn-taking prediction by \cite{deRuiter2006}. This was done by performing the same experiment but with instances of questions with equal syntactic completion points but different turn-shift locations (e.g. Are you a student? vs. Are you a student at university?). They found that in cases of syntactical ambiguity, lexicosyntactic information is not sufficient for turn-end projection and as such they claim intonation plays a role of disambiguation.  

The findings of \cite{BogTor2015} also suggest that listeners look out for turn-taking cues that are present later on within an utterance. These turn-taking cues are both lexicosyntactic and intonational. This suggests a more complicated psycholinguistic model of turn-taking that is explored within \cite{LevTor2015} where the planning of content is begun once the intention of the content is determined. As such the content is prepared and with the perception of turn completion, whether by syntactic, pragmatic or prosodic completeness, the utterance is produced. \cite{LevTor2015} suggests that the listener may specifically look for syntactic and prosodic completeness to determine when to speak. 

\section{Models for End-of-Turn Detection and Prediction}
The tradition around conversational systems' turn-taking ability is based on the existence of a silence threshold. In these models a turn is assumed to have been yielded by the current speaker once some threshold has been past (around 650ms). However, as it is to be expected, this approach yields sluggish or possibly, mistaken interruptions. As discussed above, human-human turn-taking organisation is complicated and nuanced and as such the models generated should aim to be able to utilise the signals available in conversation.

\subsection{Classification-based Models}
Further research brought this idea into fruition with what could be interpreted as 'IPU-based' models. An \texttt{Interpausal Unit (IPU)} is a segmented part of continuous speech without silence exceeding a certain threshold (200ms). IPU-based models still undertake some form of silence detection, just with a shorter threshold than a pure-silence model, and after sufficient silence has been detected the model predicts whether the silence is a TRP or a non-TRP and as such whether the turn has been yielded by the speaker.

Naturally, these models resembled the natural progression of state-of-the art machine learning models moving from rule-based classifier \cite{Bell2001}, to a decision-tree classifier \cite{Sato2002, Ferrer2002, Schlangen2006, Meena2014, Raux2008} and then now onto deep learning architectures including the use of an LSTM RNN architecture \cite{Maier2017}. 
Each model uses a different set of features and found varying results on the effectiveness of various prosodic, lexicosyntactic and pragmatic features. Specifically \cite{Sato2002} and \cite{Meena2014} found that prosody did not contribute significantly to a decision while \cite{Ferrer2002} and \cite{Schlangen2006} found that syntactic and prosodic features both contribute to turn-taking accuracy.

Models such as \cite{Sato2002, Schlangen2006, Meena2014} specifically use silence thresholds that are fixed in size. As such, if the speaker yields their turn and if the model does not detect an end of turn then a state of silence may continue.
As such other models such as \cite{Ferrer2002, Raux2008} incorporate silence length in order to continuously condition a response based on the time of silence and as such the longer after a pause the more likely that the turn has in fact been yielded. \cite{Raux2008}, took this step further by also using turn-holding cues in order to condition the silence threshold so when more turn-holding cues are detected, the system will wait longer before considering a turn-shift event. 

This process of monitoring speaker cues, to determine a turn-holding intention \cite{Raux2008}, introduced the concept of a continuous model to monitor turn-taking. An approach which has been all the more feasible with advances in both deep learning architectures and more powerful feature extractors or pretrained features. Rather than taking on a traditional approach of classifying an utterance, the continuous model processes an utterance incrementally so that at any point the model is able to predict the likelihood of a turn-shift. The system bares more symmetry with our human-human interactions as the system could be able to project turn-completions, determine intent or action and generate an appropriate response. 

\subsection{Continuous Models}
Another issue with previous approaches to turn-taking, namely the classification approach, is the availability of data that is accurately annotated. As well as this, speech data can be noisy as noted by \cite{Sacks1974} overlapping speech is common but brief, and these sections of speech should not constitute a turn-shift and so this has to be annotated well in data. 
Recognising this issue, \cite{Skantze2017} proposed a general, continuous turn-taking model, that was trained in a self-supervised manner. Self-supervised as the model is predicting the voice activity of separate speakers over the next two seconds and so it is able to predict a turn-shift based on this speech activity data. The model is also continuous in that it makes these predictions in 50ms intervals.

Others have also adopted the general LSTM approach \cite{Maier2017, Roddy2018a} to investigate the effectiveness of certain features. The general consensus is that both features in conjunction are required for superior performance however \cite{Roddy2018a} found that acoustic features are more beneficial and \cite{Maier2017} found that using only linguistic features was in fact worse than the baseline used. 
\cite{Roddy2018b} introduced a multiscale approach where linguistic and prosodic features are processed with different temporal speeds, linguistic features at slower time frames, which yielded better results than the previous baseline provided by both \cite{Roddy2018a, Skantze2017} suggesting that the considering the two features at different granularities can provide additional benefits. 

In order to seek improvements over these deep learning approaches it is imperative to discuss the quality of features in use. Prosodic features are generally a far more concrete cue to consider than linguistic features. Semantics of a conversation is difficult for models to discern as natural language is complex and ambiguous and any one intention can be represented in a variety of different word formations making overall semantics and pragmatics generated by individual linguistic tokens difficult to capture. As such, linguistic feature representation within \cite{Roddy2018a, Skantze2017, Maier2017} have been simplistic or in some cases non-existent \cite{Ward2018}. \cite{Skantze2017} solely used POS tags. \cite{Roddy2018a} used a linear neural network to generate embeddings specific for turn-taking and \cite{Maier2017} used an enriched language model, trained by predicting a hidden word and in this case a special token representing the end of a turn. 

This usage of a special token is a step undertaken by TurnGPT (\cite{Ekstedt2020}). Stronger language models allows for greater pragmatic and semantics and various contexts to be captured and by using these enhanced embeddings the predictive power of linguistic features will increase. TurnGPT is based on Open AI's GPT-2 (\cite{Radford2019}) which has been pretrained on a next-word prediction task and as such TurnGPT performs additional finetuning by the addition of speaker tokens and a special token indicating the end of a turn. The model shows increased performance when considering context as well as a greater consideration of pragmatic completeness over its LSTM baseline.  

Open AI's GPT-2 (\cite{Radford2019}) is based on the transformer decoder (\cite{Liu2018}) structure while \texttt{Bidirectional Encoder Representations from Transformers (BERT)}(\cite{}) is based primarily on the original transformer architecture (\cite{Vaswani2017}), the main difference is that BERT is able to utilize bidirectional self-attention whereas the GPT in a general sense can only be used in an autoregressive manner, so by attending to context on the left. BERT is trained based off of two tasks, Mask LM, where the model predicts 15\% unknown tokens and next sentence prediction.

\cite{Ekstedt2020} suggest that by generating responses using GPT-2's primary function of generating output, the system can predict how long it will be until a turn-completion by generating multiple possible outputs. This idea was furthered by \cite{Jiang2023} who proposed, RC-TurnGPT, which augments TurnGPT's training procedure by using the previous context and the next utterance in order to generate the probability of a turn shift. This extension of context allows for more considered turn-taking where the model does not take a turn at an early completion point. This could, for example, be a statement followed by a question. As such it explore the room of exploration that could be achieved by considering both directions of contextual history and future in producing a turn-shift prediction.  

\chapter{Your next chapter}

A dissertation usually contains several chapters.

\chapter{Conclusions}

\section{Final Reminder}

The body of your dissertation, before the references and any appendices,
\emph{must} finish by page~40. The introduction, after preliminary material,
should have started on page~1.

You may not change the dissertation format (e.g., reduce the font size, change
the margins, or reduce the line spacing from the default single spacing). Be
careful if you copy-paste packages into your document preamble from elsewhere.
Some \LaTeX{} packages, such as \texttt{fullpage} or \texttt{savetrees}, change
the margins of your document. Do not include them!

Over-length or incorrectly-formatted dissertations will not be accepted and you
would have to modify your dissertation and resubmit. You cannot assume we will
check your submission before the final deadline and if it requires resubmission
after the deadline to conform to the page and style requirements you will be
subject to the usual late penalties based on your final submission time.

% \bibliographystyle{plain}
\bibliographystyle{plainnat}
\bibliography{mybibfile}


% You may delete everything from \appendix up to \end{document} if you don't need it.
\appendix

\chapter{First appendix}

\section{First section}

Any appendices, including any required ethics information, should be included
after the references.

Markers do not have to consider appendices. Make sure that your contributions
are made clear in the main body of the dissertation (within the page limit).

\chapter{Participants' information sheet}

If you had human participants, include key information that they were given in
an appendix, and point to it from the ethics declaration.

\chapter{Participants' consent form}

If you had human participants, include information about how consent was
gathered in an appendix, and point to it from the ethics declaration.
This information is often a copy of a consent form.


\end{document}
