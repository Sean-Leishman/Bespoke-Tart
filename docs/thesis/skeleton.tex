% UG project example file, February 2022
%   A minior change in citation, September 2023 [HS]
% Do not change the first two lines of code, except you may delete "logo," if causing problems.
% Understand any problems and seek approval before assuming it's ok to remove ugcheck.
\documentclass[logo,bsc,singlespacing,parskip]{infthesis}
\usepackage{ugcheck}

% Include any packages you need below, but don't include any that change the page
% layout or style of the dissertation. By including the ugcheck package above,
% you should catch most accidental changes of page layout though.

\usepackage{microtype} % recommended, but you can remove if it causes problems
\usepackage{natbib} % recommended for citations

\begin{document}
\begin{preliminary}

\title{End-of-Turn Detection}

\author{Sean Leishman}

% CHOOSE YOUR DEGREE a):
% please leave just one of the following un-commented
%\course{Artificial Intelligence}
%\course{Artificial Intelligence and Computer Science}
%\course{Artificial Intelligence and Mathematics}
%\course{Artificial Intelligence and Software Engineering}
%\course{Cognitive Science}
%\course{Computer Science}
%\course{Computer Science and Management Science}
%\course{Computer Science and Mathematics}
%\course{Computer Science and Physics}
%\course{Software Engineering}
\course{Master of Informatics} % MInf students

% CHOOSE YOUR DEGREE b):
% please leave just one of the following un-commented
\project{MInf Project (Part 1) Report}  % 4th year MInf students
%\project{MInf Project (Part 2) Report}  % 5th year MInf students
%\project{4th Year Project Report}        % all other UG4 students


\date{\today}

\abstract{
This skeleton demonstrates how to use the \texttt{infthesis} style for
undergraduate dissertations in the School of Informatics. It also emphasises the
page limit, and that you must not deviate from the required style.
The file \texttt{skeleton.tex} generates this document and should be used as a
starting point for your thesis. Replace this abstract text with a concise
summary of your report.
}

\maketitle

\newenvironment{ethics}
   {\begin{frontenv}{Research Ethics Approval}{\LARGE}}
   {\end{frontenv}\newpage}

\begin{ethics}
\textbf{Instructions:} \emph{Agree with your supervisor which
statement you need to include. Then delete the statement that you are not using,
and the instructions in italics.\\
\textbf{Either complete and include this statement:}}\\ % DELETE THESE INSTRUCTIONS
%
% IF ETHICS APPROVAL WAS REQUIRED:
This project obtained approval from the Informatics Research Ethics committee.\\
Ethics application number: ???\\
Date when approval was obtained: YYYY-MM-DD\\
%
\emph{[If the project required human participants, edit as appropriate, otherwise delete:]}\\ % DELETE THIS LINE
The participants' information sheet and a consent form are included in the appendix.\\
%
% IF ETHICS APPROVAL WAS NOT REQUIRED:
\textbf{\emph{Or include this statement:}}\\ % DELETE THIS LINE
This project was planned in accordance with the Informatics Research
Ethics policy. It did not involve any aspects that required approval
from the Informatics Research Ethics committee.

\standarddeclaration
\end{ethics}


\begin{acknowledgements}
Any acknowledgements go here.
\end{acknowledgements}


\tableofcontents
\end{preliminary}


\chapter{Introduction}

The preliminary material of your report should contain:
\begin{itemize}
\item
The title page.
\item
An abstract page.
\item
Declaration of ethics and own work.
\item
Optionally an acknowledgements page.
\item
The table of contents.
\end{itemize}

As in this example \texttt{skeleton.tex}, the above material should be
included between:
\begin{verbatim}
\begin{preliminary}
    ...
\end{preliminary}
\end{verbatim}
This style file uses roman numeral page numbers for the preliminary material.

The main content of the dissertation, starting with the first chapter,
starts with page~1. \emph{\textbf{The main content must not go beyond page~40.}}

The report then contains a bibliography and any appendices, which may go beyond
page~40. The appendices are only for any supporting material that's important to
go on record. However, you cannot assume markers of dissertations will read them.

You may not change the dissertation format (e.g., reduce the font size, change
the margins, or reduce the line spacing from the default single spacing). Be
careful if you copy-paste packages into your document preamble from elsewhere.
Some \LaTeX{} packages, such as \texttt{fullpage} or \texttt{savetrees}, change
the margins of your document. Do not include them!

Over-length or incorrectly-formatted dissertations will not be accepted and you
would have to modify your dissertation and resubmit. You cannot assume we will
check your submission before the final deadline and if it requires resubmission
after the deadline to conform to the page and style requirements you will be
subject to the usual late penalties based on your final submission time.

\chapter{Background Review}
\section{Turn-taking: From the Conversational Analysis Perspective}
Over the last few decades, psycholinguists have been fascinated with the complexity of the mechanisms of conversation along with the apparent ease with which speaker's are able to converse in a orderly and timely manner. 
\cite{Sacks1974} is a widely cited paper that outlines some general observations that has gone on to inform general turn-taking literature. They observed that turn-taking organisation is not planned in advance however the actions taken are still coordinated, in a flexible manner that can be decided upon by the current participants in a conversation; typically one person speaks at a time and most transitions have a small gap or overlap but transitions do also occur with no gap and no overlap. 
Automatic analysis has managed to substantiate these claims with the existence of generally short turns (mean 1680ms, median 1227ms) (\cite{LevTor2015}) and that, the majority of turn transitions (51\%-55\%) take places under 200ms (\cite{HelEdl2010}). An even greater majority of turn transitions take place between -100ms and 500ms (\cite{LevTor2015}). Turn-taking is finely tuned and managed.

\subsection{Models of Turn-taking Organisation} 
Turn-taking organisation has generally been characterised in two different ways within literature: the \texttt{reactionary} and the \texttt{predictive} approach.
The former assumes that participants simply understand end-of-turn signals and react to them accordingly while the predictive approach entails the listener predicting the end of turn in advance such that responses are well timed. 

The reactionary approach assumes that turn-taking organisation is regulated by both vocal and gestural signals (\cite{Yngve1970}). This approach was pioneered by (\cite{Duncan1972, Duncan1973, Duncan1974, Duncan1977}) who argued for a precise set of context free turn-yielding 'signals'. \cite{Duncan1972} described phrase-final intonation, drawl on the final syllable, termination of hand gesticulation, changes in pitch and a termination of a grammatical clause as turn-yielding signals. 

Others have argued against the general model of a reactionary approach as, put simply, turn-transitions occur too quickly and turn-yielding signals occur too late within a speaker's utterance for the listener to simply react to an end-of-turn signal (\cite{LevTor2015, Riest2015}). (It is important to note that the \texttt{reactionary} approach is only dismissed in the context of the entire psycholinguistic model where both production and comprehension is considered.) 

\cite{Sacks1974} pioneered the \texttt{predictive} approach and in their analysis of turn-taking argued that the observed speed of turn-transitions required some form of `projection` with the production of language beginning prior to the end of a turn. This model of turn-taking is based off of separating speech into units, where one participant is the speaker, called \texttt{Turn Construction Units (TCU)} and immediately after completing a TCU a \texttt{Transition Relevance Place (TRP)} occurs that signals that a turn-transition (turn-shift) can occur. It is also important to note that a TRP does not always result in a turn-shift and a turn-shift does not always occur at a TRP. 

\iffalse
Nevertheless, every TRP is governed by a set of rules determining whether or not a TRP will result in a turn-shift: 
\begin{enumerate}
    \item{} The current speaker may select a new speaker during which the other participants act as listeners 
    \item{} If the current speaker does not select then any participant can self-select. The first to start gains the turn.
    \item{} If no other party self-selects, the current speaker may continue. 
\end{enumerate} 


The rules highlights an interesting property of turn-taking, first noted by \cite{Sacks1974} and verified by \cite{tenBosch2005}, that intra-speaker gaps (gaps within the same utterance) are longer than inter-speaker gaps (gap resulting in a turn-shift) by around 25\%.
\fi
\cite{Sacks1974} note that in order for a listener to project the end-of-turn than the speaker would have to construct their turns, with successive TCUs, in such a way that a turn transition is foreshadowed, showing that the turn is, in effect, winding down.

Some effort has been taken by \cite{HelEdl2010} to critique the \texttt{predictive} approach.  
This claim originates from the number of turn transitions above 200ms (41\%-45\% \cite{HelEdl2010}) and that, for these turn transitions, listeners are reacting to silence. \cite{LevTor2015} comprehensibly dismisses the claim by stating that comprehension and production takes at minimum 550ms, outside the normal range of turn transitions. In addition to this, \cite{Riest2015} point out that the presence of longer gaps could be explained by a speaker intentionally delaying a response when producing a 'dispreferred' response.

\subsection{Turn-taking Cues}
The question remains, what features of speech are relevant when predicting a TCU completion and, as such, when completing a turn? 
Prior research related to turn-yielding signals (\cite{Duncan1972}), pointed out prosodic, syntactic and gestural features that coincide with turn-completion at an end-of-turn. Later work focussed on these turn-yielding signals and which signals contribute in a meaningful manner such that the listener is able to project a turn-completion. 
Most work has focussed on three aspects of conversation: syntactic, prosodic and pragmatic features. Gestural features (\cite{Duncan1972}) and gaze (\cite{Kendon1967}) have shown to be a useful part of turn-taking but findings in gaze have suggested these features are action dependent and more context-sensitive than other features (\cite{Clayman2013}).

Although \cite{Sacks1974} left solving the question of how projection occurs they suggested that syntax to future research but they suggested that syntax and semantics contributed more due to the projectibility of syntactic units as compared to the projectibility of prosodic units. 

The complex nature of turn-taking and the constraints imposed by language production means that turn-taking cues have to be early enough in order to determine a turn-completion and then to generate some kind of response \cite{LevTor2015}. With knowledge of these temporal requirements, \cite{deRuiter2006} found that end-of-turn prediction was unaffected by the removal of intonational contours but it was affected by the removal of lexicosyntactic information. 
This study was backed up by \cite{Magyari2012} that showed when participants predicted the remaining part of a sentence, this prediction was more accurate if the end-of-turn prediction was also accurate. This suggests that the listener uses a predicted utterance to determine turn-completion. 

This belief was also highlighted by \cite{PicGar2013} who found that listeners actually imitate the speaker to determine intention and as such the content which is combined with the speaker's speaking rate to correctly time their own prepared utterance.

The reliance on lexicosyntactic information, especially in a predictive framework, is well-founded as according to \cite{Sacks1974} syntactic units is a more feasible unit to project than prosodic units. 
Syntactic completeness is important as \cite{Ford1996} found that most TRPs occur at syntactic completion points. 
\cite{Ford1996} defined an utterance is syntactically complete if "in its discourse context, it could be interpreted as a complete clause, that is, with an overt or directly recoverable predicate, without considering intonation or interactional import".
While syntax is rooted in linguistic structure pragmatics has more to do with conversational context and intention. 
In their analysis \cite{Ford1996} defined an utterance as pragmatically complete if it is a "complete conversational action within a sequential context".
As such it means that we can judge whether an utterance has fulfilled its purpose within conversation such as when answering questions.

The following example demonstrates the many possible syntactic completion points while showing that pragmatic completion demonstrates a more nuanced selection of possible TRP locations: 
\begin{quote}
    V: And his knee was being worn/- okay/ wait./
    It was bent/ that way/
\end{quote}

\cite{Ford1996} theorised that TCUs and their partnering TRPs are a complex notion and as such multiple factors should be considered for predicting a turn completion. This belief was tested by \cite{BogTor2015} who also sought to refute the claim that intonation had no effect on turn-taking prediction by \cite{deRuiter2006}. This was done by performing the same experiment but with instances of questions with equal syntactic completion points but different turn-shift locations (e.g. Are you a student? vs. Are you a student at university?). They found that in cases of syntactical ambiguity, lexicosyntactic information is not sufficient for turn-end projection and as such they claim intonation plays a role of disambiguation.  

The findings of \cite{BogTor2015} also suggest that listeners look out for turn-taking cues that are present later on within an utterance. These turn-taking cues are both lexicosyntactic and intonational. This suggests a more complicated psycholinguistic model of turn-taking that is explored within \cite{LevTor2015} where the planning of content is begun once the intention of the content is determined. As such the content is prepared and when an end-of-turn is signalled, whether by syntactic, pragmatic or prosodic completeness, the utterance is produced.

\subsection{Overlaps} 
As noted by \cite{Sacks1974} overlaps are common within TCUs but these occurances are brief and so they are not sufficient enough to constitute a turn. Turn-taking models and systems should account for the addition of backchannels.

\section{Models for End-of-Turn Detection and Prediction}
The tradition around conversational systems' turn-taking ability is based on the existence of a silence threshold. In these models a turn is assumed to have been yielded by the current speaker once some threshold has been past (around 650ms). However, as it is to be expected, this approach yields sluggish or possibly, mistaken interruptions. As discussed above, human-human turn-taking organisation is complicated and nuanced and as such the models generated should aim to be able to utilise the signals available in conversation.

\subsection{Classification-based Models}
Further research brought more nuanced 'IPU-based' models. An \texttt{Interpausal Unit (IPU)} is a segmented part of continuous speech without silence exceeding a certain threshold (200ms). IPU-based models still undertake silence detection, just with a shorter threshold. But after a sufficient silence has been detected the model predicts whether the silence is a TRP or a non-TRP.

Naturally, these models resembled the natural progression of state-of-the art machine learning models moving from rule-based classifier \cite{Bell2001}, to a decision-tree classifier \cite{Sato2002, Ferrer2002, Schlangen2006, Meena2014, Raux2008, Koiso1998} and then now onto deep learning architectures including the use of an LSTM RNN architecture \cite{Maier2017}. 
Each model uses a different set of features and found varying results on the effectiveness of various prosodic, lexicosyntactic and pragmatic features. Specifically, \cite{Sato2002} and \cite{Meena2014} found that prosody did not contribute significantly to a decision while \cite{Ferrer2002} and \cite{Schlangen2006} found that syntactic and prosodic features both contribute to turn-taking accuracy. 
\cite{Koiso1998} found that in Japanese data, that even POS tags are powerful cues to predict turn-change.

Backchannels are also generally, an important part of conversation due to their regularity and as such \cite{Gravano2011} investigated their cues and found predictors for these events that are radically different from identifies turn-taking cues. As such modelling the two differently should be performed. 

 This highlights an issue with these styles of models in that it is a purely reactive system and so the system is not able to make decisions early in an utterance and so performant human-like gaps is not reasonable without considering the incremental alternative.  

\subsection{Continuous Models}

Rather than taking on a traditional approach of classifying an utterance, the continuous model processes an utterance incrementally so that at any point the model is able to predict the likelihood of a turn-shift. The system bares more symmetry with our human-human interactions as the system could be able to project turn-completions, determine intent or action and generate an appropriate response. 

An issue with previous approaches to turn-taking, namely the classification approach, is the availability of data that is accurately annotated. As well as this, speech data can be noisy as noted by \cite{Sacks1974} overlapping speech is common but brief, and these sections of speech should not constitute a turn-shift and so this has to be annotated well in data.

Recognising this issue, \cite{Skantze2017} proposed a general, continuous turn-taking model, that was trained in a self-supervised manner. Self-supervised as the model is predicting the voice activity of separate speakers over the next two seconds and so it is able to predict a turn-shift based on this speech activity data. The model is also continuous in that it makes these predictions in 50ms intervals.

Others have also adopted the general LSTM approach (\cite{Maier2017, Roddy2018a}) to investigate the effectiveness of certain features. The general consensus is that both features in conjunction are required for superior performance however \cite{Roddy2018a} found that acoustic features are more beneficial and \cite{Maier2017} found that using only linguistic features was in fact worse than their baseline result. 

In order to seek improvements over these deep learning approaches it is imperative to discuss the quality of features in use. Prosodic features are generally a far more concrete cue to consider than linguistic features. The semantics of a conversation is difficult for models to discern as natural language is complex and ambiguous and any one intention can be represented in a variety of different word formations making overall semantics and pragmatics generated by individual linguistic tokens difficult to capture. As such, linguistic feature representation within \cite{Roddy2018a, Skantze2017, Maier2017} have been simplistic or in some cases non-existent (\cite{Ward2018}). \cite{Skantze2017} solely used POS tags. \cite{Roddy2018a} used a linear neural network to generate embeddings specific for turn-taking and \cite{Maier2017} used an enriched language model, trained by predicting a hidden word and in this case a special token representing the end of a turn. 

Although the execution is different the idea of a special token to discern speaker changes is a step undertaken by TurnGPT (\cite{Ekstedt2020}). Stronger language models allows for greater pragmatic and semantics and various contexts to be captured and by using these enhanced embeddings the predictive power of linguistic features will increase. TurnGPT is based on Open AI's GPT-2 (\cite{Radford2019}) which has been pretrained on a next-word prediction task and TurnGPT performs additional finetuning by the addition of speaker tokens and a special token indicating the end of a turn. The model shows increased performance when considering context of previous turns as well as a greater consideration of pragmatic completeness over its LSTM baseline where 20\% of its attention is directed towards earlier utterances.

Open AI's GPT-2 (\cite{Radford2019}) is based on the transformer decoder (\cite{Liu2018}) structure while \texttt{Bidirectional Encoder Representations from Transformers (BERT)}(\cite{}) is based primarily on the original transformer architecture (\cite{Vaswani2017}), the main difference is that BERT is able to utilize bidirectional self-attention whereas the GPT in a general sense can only be used in an autoregressive manner, so by attending to context on the left. 

\cite{Ekstedt2020} suggest that by generating responses using GPT-2's primary function of generating output, the system can predict how long it will be until a turn-completion by generating multiple possible outputs. This idea was furthered by \cite{Jiang2023} who proposed, RC-TurnGPT, which augments TurnGPT's training procedure by using the previous context and the next utterance in order to generate the probability of a turn shift. This extension of context allows for more considered turn-taking where the model does not take a turn at an early completion point. This could, for example, be a statement followed by a question.
As such it partially explore what could be achieved by considering both directions of contextual history and future in producing a turn-shift prediction.  

\chapter{Your next chapter}

A dissertation usually contains several chapters.

\chapter{Conclusions}

\section{Final Reminder}

The body of your dissertation, before the references and any appendices,
\emph{must} finish by page~40. The introduction, after preliminary material,
should have started on page~1.

You may not change the dissertation format (e.g., reduce the font size, change
the margins, or reduce the line spacing from the default single spacing). Be
careful if you copy-paste packages into your document preamble from elsewhere.
Some \LaTeX{} packages, such as \texttt{fullpage} or \texttt{savetrees}, change
the margins of your document. Do not include them!

Over-length or incorrectly-formatted dissertations will not be accepted and you
would have to modify your dissertation and resubmit. You cannot assume we will
check your submission before the final deadline and if it requires resubmission
after the deadline to conform to the page and style requirements you will be
subject to the usual late penalties based on your final submission time.

% \bibliographystyle{plain}
\bibliographystyle{plainnat}
\bibliography{mybibfile}


% You may delete everything from \appendix up to \end{document} if you don't need it.
\appendix

\chapter{First appendix}

\section{First section}

Any appendices, including any required ethics information, should be included
after the references.

Markers do not have to consider appendices. Make sure that your contributions
are made clear in the main body of the dissertation (within the page limit).

\chapter{Participants' information sheet}

If you had human participants, include key information that they were given in
an appendix, and point to it from the ethics declaration.

\chapter{Participants' consent form}

If you had human participants, include information about how consent was
gathered in an appendix, and point to it from the ethics declaration.
This information is often a copy of a consent form.


\end{document}
